{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "813f2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from requests.auth import HTTPProxyAuth\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e86c90f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m page_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://mall.elady.com/items/category/BAGS/?limit=120\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m proxy_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproxy_username\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproxy_password\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproxy_host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproxy_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 14\u001b[0m current_time \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melady_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproduct_info\u001b[39m(product_url, retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "proxy_host = '184.174.24.237'  \n",
    "proxy_port = '6813'              \n",
    "proxy_username = 'fjhdetvm'  \n",
    "proxy_password = 'dj626ier4ofb'  \n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "page_url = 'https://mall.elady.com/items/category/BAGS/?limit=120'\n",
    "\n",
    "proxy_url = f'http://{proxy_username}:{proxy_password}@{proxy_host}:{proxy_port}'\n",
    "\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "csv_file = f'elady_{current_time}.csv'\n",
    "\n",
    "def product_info(product_url, retry = 3):\n",
    "    if retry ==0:\n",
    "        return None\n",
    "    try:\n",
    "        if not product_url.startswith('http'):\n",
    "            raise ValueError(\"Invalid product URL\")\n",
    "        \n",
    "        response = requests.get(product_url, proxies={'http': proxy_url, 'https': proxy_url}, headers=headers,auth=HTTPProxyAuth(proxy_username, proxy_password))\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to retrieve {product_url}, status code: {response.status_code}\")\n",
    "            \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        product_name = soup.find('div',class_='detail__name').text.strip()\n",
    "\n",
    "        product_price = soup.find('span',class_='price').text.strip()\n",
    "\n",
    "        sku = soup.find('p',class_='detail__code').text.replace('SKU:','').strip()\n",
    "\n",
    "        main_image = soup.find('img',id='image-main').get('src')\n",
    "\n",
    "        brand, line, product_type, material, color, closure, inner_pocket, gender, size, handle_length, strap_length = None, None, None, None, None, None, None, None, None, None, None \n",
    "        all_x_td = soup.find('div', id = 'detail_param_content1').find_all('td', class_='y')\n",
    "        all_x_td = [i for i in all_x_td if i.text != '']\n",
    "        all_y_td = soup.find('div', id = 'detail_param_content1').find_all('td', class_='x')\n",
    "        for num in range(len(all_x_td)):\n",
    "            key = all_x_td[num].text\n",
    "            values = all_y_td[num].find_all('tr')\n",
    "            if len(values)>1:\n",
    "                value = ', '.join([i.text.strip() for i in values if hasattr(i, 'text') and i.text != '']).strip()\n",
    "            else:\n",
    "                value = values[0].text.strip()\n",
    "\n",
    "            if key == 'Brand':\n",
    "                brand = value\n",
    "            elif key == 'Line':\n",
    "                line = value\n",
    "            elif key == 'Model':\n",
    "                model = value\n",
    "            elif key == 'Country of Origin':\n",
    "                country_of_origin = value\n",
    "            elif key == 'Type':\n",
    "                product_type = value\n",
    "            elif key == 'Material':\n",
    "                material = value\n",
    "            elif key == 'Leather/Fur Type':\n",
    "                leather_or_fur_type = value\n",
    "            elif key == 'Color':\n",
    "                color = value\n",
    "            elif key == 'Closure':\n",
    "                closure = value\n",
    "            elif key == 'Inner Pocket':\n",
    "                inner_pocket = value\n",
    "            elif key == 'Gender':\n",
    "                gender = value\n",
    "            elif key == 'Size (HxWxD)':\n",
    "                size = value\n",
    "            elif key == 'Handle Length':\n",
    "                handle_length = value\n",
    "            elif key == 'Strap Length':\n",
    "                strap_length = value\n",
    "\n",
    "        all_x_td = soup.find('div', id = 'detail_param_content2').find_all('td', class_='y')\n",
    "        all_x_td = [i for i in all_x_td if i.text != '']\n",
    "        all_y_td = soup.find('div', id = 'detail_param_content2').find_all('td', class_='x')\n",
    "\n",
    "        accessories, condition = None, None\n",
    "        for num in range(len(all_x_td)):\n",
    "            key = all_x_td[num].text\n",
    "            values = all_y_td[num].find_all('tr')\n",
    "            if len(values)>1:\n",
    "                value = ', '.join([i.text.strip() for i in values if hasattr(i, 'text') and i.text != '']).strip()\n",
    "            else:\n",
    "                value = values[0].text.strip()\n",
    "\n",
    "            if key == 'Accessories':\n",
    "                accessories = value\n",
    "            elif key == 'Condition':\n",
    "                condition = value\n",
    "\n",
    "        di = {'product_name':product_name, 'product_price':product_price, 'sku':sku, 'main_image':main_image,\n",
    "         'brand':brand, 'line':line, 'model':model, 'country_of_origin':country_of_origin, 'product_type':product_type, 'material':material, \n",
    "              'leather_or_fur_type':leather_or_fur_type, 'color':color, 'closure':closure,\n",
    "          'inner_pocket':inner_pocket, 'gender':gender, 'size':size, 'handle_length':handle_length, 'strap_length':strap_length,\n",
    "             'accessories':accessories, 'condition':condition}\n",
    "        return di\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in product_info for {product_url}: {e}\")\n",
    "        print('Retrying this URL again!!, Remaining retry: ',retry)\n",
    "        return product_info(product_url, retry-1)\n",
    "        \n",
    "    \n",
    "\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    \n",
    "    fieldnames = ['product_name', 'product_price', 'sku', 'main_image', 'brand', 'line', 'model', 'country_of_origin', 'product_type', 'material', \n",
    "                  'leather_or_fur_type', 'color',\n",
    "                  'closure', 'inner_pocket', 'gender', 'size', 'handle_length', 'strap_length', 'accessories', 'condition']\n",
    "    \n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(page_url, proxies={'http': proxy_url, 'https': proxy_url}, headers=headers,auth=HTTPProxyAuth(proxy_username, proxy_password))\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(f\"Failed to retrieve page, status code: {response.status_code}\")\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            try:\n",
    "                page_url = 'https://mall.elady.com'+soup.find('a', title='Next').get('href')\n",
    "            except:\n",
    "                page_url = None\n",
    "\n",
    "            urls = soup.find_all('a', class_='item_archive__link')\n",
    "\n",
    "            for url in urls:\n",
    "                product_url = 'https://mall.elady.com' + url.get('href')\n",
    "                print(product_url)\n",
    "                product_data = product_info(product_url)\n",
    "                \n",
    "                if product_data:\n",
    "                    writer.writerow(product_data)\n",
    "                    file.flush()  \n",
    "                    \n",
    "                length = sum(1 for _ in open(csv_file)) - 1  # Subtract 1 to exclude the header\n",
    "                print(f\"Current CSV length (excluding header): {length}\")\n",
    "                \n",
    "            if page_url == None:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error while processing page: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e5fa0063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ad879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
